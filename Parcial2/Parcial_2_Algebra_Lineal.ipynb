{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1nTHfutKGGmMMrTp4kW4x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaiderSantos/metodos1_JaiderSantos_NicolasGomez/blob/main/Parcial2/Parcial_2_Algebra_Lineal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YJgAcUU1Ezcr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy as sym\n",
        "import numpy as np\n",
        "from scipy import integrate\n",
        "import math as math\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import roots_legendre\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "import copy\n",
        "\n",
        "C = np.array([8.51, 10.68, 12.24, 13.66, 15.37, 17.15, 19.66, 24.69])\n",
        "Ca = 1000000\n",
        "\n",
        "\n",
        "def func_de_retorno(C, w, Ca):\n",
        "\n",
        "    w = np.resize(w, C.shape)\n",
        "    Pro_elem = w * C\n",
        "    menos1 = Pro_elem - 1\n",
        "    RTA = np.min(Ca * (menos1))\n",
        "    return RTA\n",
        "\n",
        "\n",
        "def func_de_retorno_max(C, w, Ca):\n",
        "\n",
        "    w = np.resize(w, C.shape)\n",
        "    Pro_elem = w * C\n",
        "    menos1 = Pro_elem - 1\n",
        "    RTA = Ca * np.max(menos1)\n",
        "    return RTA\n",
        "\n",
        "\n",
        "class Robot:\n",
        "    def __init__(self, f, Id, T):\n",
        "        self.Id = Id\n",
        "        self.f = f\n",
        "        self.h = np.zeros(T)\n",
        "        for i in range(T):\n",
        "            self.h[i] = np.random.uniform(1.0, 100.0)\n",
        "        self.h /= np.sum(self.h)\n",
        "\n",
        "        self.r = np.random.rand(len(C))\n",
        "        self.rate = 0.05\n",
        "\n",
        "\n",
        "    def Mutate(self):\n",
        "        self.r += np.random.normal(loc=0., scale=self.rate, size=len(self.r))\n",
        "\n",
        "    def GetR(self):\n",
        "        return self.r\n",
        "\n",
        "    def SetFitness(self):\n",
        "        self.Fitness = self.f(C, self.GetR(), Ca)\n",
        "\n",
        "\n",
        "        if self.Fitness > 0.05:\n",
        "            self.rate = 0.005\n",
        "\n",
        "    def GetFitness(self):\n",
        "        return self.Fitness\n",
        "\n",
        "\n",
        "def GetRobots(N, tam):\n",
        "    Robots = []\n",
        "\n",
        "    for i in range(N):\n",
        "        r = Robot(func_de_retorno, i, tam)\n",
        "        Robots.append(r)\n",
        "\n",
        "    return Robots\n",
        "\n",
        "\n",
        "Robots = np.array(GetRobots(500, len(C)))\n",
        "\n",
        "\n",
        "def GetRobots(N, tam):\n",
        "    Robots = []\n",
        "\n",
        "    for i in range(N):\n",
        "        r = Robot(func_de_retorno, i, tam)\n",
        "        Robots.append(r)\n",
        "\n",
        "    return Robots\n",
        "\n",
        "\n",
        "Robots = np.array(GetRobots(50, len(C)))\n",
        "\n",
        "for i in range(len(Robots)):\n",
        "    print(Robots[i].h)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Genetic(Robots, epochs = 500):\n",
        "\n",
        "\n",
        "\n",
        "    N = int(0.5*len(Robots))\n",
        "\n",
        "\n",
        "    Fitness = np.array([])\n",
        "\n",
        "    for e in range(int(epochs)):\n",
        "\n",
        "\n",
        "        for i,p in enumerate(Robots):\n",
        "            p.Mutate()\n",
        "            p.SetFitness()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        scores = [ (p.Fitness, p) for p in Robots ]\n",
        "        scores.sort(key = lambda x: x[0], reverse = False)\n",
        "\n",
        "\n",
        "        Temp = [r[1] for i,r in enumerate(scores) if i < N ]\n",
        "\n",
        "        for i,r in enumerate(Robots):\n",
        "            j = i%N\n",
        "            Robots[i] = copy.deepcopy(Temp[j])\n",
        "\n",
        "\n",
        "\n",
        "        Fitness_ = [  r.GetFitness() for i,r in enumerate(Robots) ]\n",
        "\n",
        "\n",
        "        Fitness = np.append(Fitness,np.mean(Fitness_))\n",
        "\n",
        "        if Fitness[-1] < 0.0001:\n",
        "            break\n",
        "\n",
        "\n",
        "        if e % 10 == 0:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            ax,ax1 = Plotter(e)\n",
        "            for i,p in enumerate(Robots):\n",
        "                ax.scatter(p.GetR()[0],p.GetR()[1],marker='.',color='r',label='Id {}'.format(p.Id))\n",
        "            ax.set_xlim(-5,5)\n",
        "            ax.set_ylim(-5,5)\n",
        "\n",
        "\n",
        "            ax1.set_title('Fitness function')\n",
        "            ax1.plot(Fitness,color='k',label='Id {}, {:.2f}, {:.2f}, {:.2f}'.format(Robots[0].Id, Robots[0].GetR()[0],Robots[0].GetR()[1],Robots[0].GetR()[2]))\n",
        "            ax1.set_xlabel('Epoch')\n",
        "            ax1.legend(loc=1)\n",
        "\n",
        "            plt.show()\n",
        "Genetic(Robots)\n",
        "\n",
        "params = np.array([ p.GetR() for i, p in enumerate(Robots)]).mean(axis=0)\n",
        "\n",
        "print(params)\n",
        "\n",
        "\n",
        "\n",
        "Pesos = np.array([0.185, 0.152, 0.137, 0.125, 0.116, 0.107, 0.096, 0.082])\n",
        "print(Pesos)\n",
        "print(Pesos.sum())\n",
        "print()\n",
        "# ganacia minima\n",
        "min_ganancia = func_de_retorno(C, Pesos, Ca)\n",
        "print(\"En el peor de los casos el retorno seriade\",min_ganancia)\n",
        "#pocible maximo del retorno de inverciÃ³n\n",
        "max_ganancia=func_de_retorno_max(C,Pesos,Ca)\n",
        "print(\"el retorno maximo posible seria de\",max_ganancia)\n",
        "\n",
        "#cuanto se invierte en cada opcion\n",
        "invercion=np.zeros(len(Pesos))\n",
        "for i in range(len(Pesos)):\n",
        "  invercion[i]=Pesos[i]*Ca\n",
        "print(invercion)\n",
        "Total=np.sum(invercion)\n",
        "print(Total)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl0aAEGhE1b0",
        "outputId": "819ef06c-97fd-47e4-f8cf-dd029f228c13"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.18181639 0.03045363 0.20502222 0.20646555 0.01212808 0.10078726\n",
            " 0.1436682  0.11965868]\n",
            "[0.18045868 0.12202281 0.07441394 0.21029781 0.08317322 0.07780743\n",
            " 0.10244384 0.14938226]\n",
            "[0.17689379 0.15376506 0.04613931 0.1523633  0.08355676 0.15338614\n",
            " 0.20662275 0.02727289]\n",
            "[0.1929948  0.12384657 0.16979228 0.06727042 0.16543974 0.0655635\n",
            " 0.01850559 0.1965871 ]\n",
            "[0.17483967 0.21307765 0.15305551 0.0094286  0.08919856 0.10687206\n",
            " 0.13251498 0.12101298]\n",
            "[0.18348204 0.08537329 0.16007156 0.04405968 0.10337466 0.19739696\n",
            " 0.08767854 0.13856325]\n",
            "[0.02204896 0.03826634 0.07938745 0.10831871 0.08198374 0.32215251\n",
            " 0.06866242 0.27917987]\n",
            "[0.28464837 0.00388492 0.07326948 0.00735854 0.21135472 0.19714903\n",
            " 0.15344041 0.06889453]\n",
            "[0.06811197 0.15157884 0.03625156 0.07975889 0.15728539 0.15517859\n",
            " 0.22101121 0.13082353]\n",
            "[0.09594091 0.1779443  0.15453059 0.16309401 0.1647661  0.16712106\n",
            " 0.02865708 0.04794595]\n",
            "[0.04296837 0.0751848  0.08294396 0.15362165 0.20963364 0.21466771\n",
            " 0.07294668 0.14803319]\n",
            "[0.16692319 0.06000024 0.07047108 0.13331564 0.2819345  0.02863526\n",
            " 0.08955793 0.16916216]\n",
            "[0.21362278 0.17227625 0.08164103 0.14631786 0.16924999 0.05584453\n",
            " 0.09778258 0.06326498]\n",
            "[0.05224042 0.00519791 0.10367115 0.01073779 0.13294783 0.26227485\n",
            " 0.20301321 0.22991685]\n",
            "[0.11612534 0.10628874 0.1482956  0.08549985 0.17168984 0.09480876\n",
            " 0.12300646 0.15428541]\n",
            "[0.05533428 0.09509099 0.18403811 0.13002734 0.12224078 0.07449898\n",
            " 0.11456345 0.22420607]\n",
            "[0.08199067 0.07259756 0.14566323 0.11976933 0.19609587 0.14114302\n",
            " 0.17037388 0.07236644]\n",
            "[0.09123189 0.01734344 0.19548367 0.10250736 0.15301898 0.14831239\n",
            " 0.21669338 0.07540889]\n",
            "[0.06957464 0.16664111 0.06867135 0.19238445 0.22889018 0.05648668\n",
            " 0.05004868 0.16730292]\n",
            "[0.09117731 0.19898762 0.09981927 0.08881813 0.15007161 0.11803775\n",
            " 0.16175747 0.09133083]\n",
            "[0.22538713 0.05082969 0.10498568 0.16147186 0.14931145 0.13475451\n",
            " 0.13020954 0.04305014]\n",
            "[0.14581604 0.10287694 0.23442503 0.01955247 0.10839493 0.20758144\n",
            " 0.13885681 0.04249634]\n",
            "[0.03179879 0.0256281  0.0117982  0.23391764 0.1570012  0.06288028\n",
            " 0.23530859 0.24166721]\n",
            "[0.01535315 0.14178977 0.08271705 0.06125417 0.19784876 0.12308175\n",
            " 0.29577249 0.08218286]\n",
            "[0.02290119 0.10380253 0.18369483 0.20722258 0.14107537 0.09433817\n",
            " 0.14042312 0.10654221]\n",
            "[0.2764671  0.11298663 0.23390987 0.07330817 0.07542402 0.02258612\n",
            " 0.06613047 0.13918762]\n",
            "[0.01588059 0.11198543 0.10460745 0.1968143  0.22535549 0.16590449\n",
            " 0.01421029 0.16524197]\n",
            "[0.08330733 0.04112989 0.25167361 0.21341414 0.09665696 0.04947529\n",
            " 0.02102907 0.24331372]\n",
            "[0.04383038 0.13050395 0.12508564 0.09885877 0.22616074 0.18437403\n",
            " 0.09068169 0.10050481]\n",
            "[0.08989455 0.02563459 0.07536716 0.14656575 0.17461278 0.15808092\n",
            " 0.17336625 0.15647801]\n",
            "[0.0248056  0.0101799  0.26844447 0.25126498 0.05292135 0.08471032\n",
            " 0.09989432 0.20777906]\n",
            "[0.19101481 0.20896991 0.08724497 0.08379356 0.07336305 0.20481841\n",
            " 0.11594581 0.03484947]\n",
            "[0.0643906  0.05178949 0.18153202 0.20464994 0.07170695 0.15638309\n",
            " 0.15565097 0.11389694]\n",
            "[0.09886476 0.22683679 0.1235822  0.13899829 0.19519823 0.04788372\n",
            " 0.15248786 0.01614814]\n",
            "[0.10512095 0.04599864 0.01694481 0.07975212 0.2199193  0.18729717\n",
            " 0.17549429 0.16947271]\n",
            "[0.28017276 0.012188   0.06408679 0.23941512 0.35467382 0.01955693\n",
            " 0.00971086 0.02019571]\n",
            "[0.09789658 0.16257159 0.06459541 0.1460026  0.11681057 0.08177933\n",
            " 0.15757885 0.17276506]\n",
            "[0.08427905 0.12177983 0.18319076 0.1395012  0.13167243 0.06119304\n",
            " 0.07477728 0.20360641]\n",
            "[0.11892053 0.06481537 0.15087796 0.04379847 0.18881974 0.0870954\n",
            " 0.25395746 0.09171507]\n",
            "[0.07186723 0.23220232 0.06194929 0.13704126 0.1809979  0.02248528\n",
            " 0.14500145 0.14845525]\n",
            "[0.07566432 0.04388263 0.17042411 0.15859598 0.15992218 0.08478573\n",
            " 0.1789328  0.12779226]\n",
            "[0.12736047 0.11424078 0.13895355 0.19472848 0.19616732 0.02902342\n",
            " 0.06220487 0.13732111]\n",
            "[0.01568154 0.16799735 0.08367622 0.19009849 0.12824591 0.11243677\n",
            " 0.06380839 0.23805534]\n",
            "[0.0294561  0.12544936 0.05980699 0.14392377 0.35449265 0.05524843\n",
            " 0.02278465 0.20883805]\n",
            "[0.11778721 0.22154149 0.13972118 0.06588626 0.22975969 0.01464331\n",
            " 0.0868376  0.12382328]\n",
            "[0.15318994 0.0616467  0.13135498 0.19698062 0.27004325 0.09089147\n",
            " 0.01558308 0.08030996]\n",
            "[0.06799241 0.02548332 0.00747668 0.00501279 0.00996073 0.27760997\n",
            " 0.34590833 0.26055578]\n",
            "[0.00580787 0.1553465  0.1273474  0.19381697 0.19097627 0.12079654\n",
            " 0.13889129 0.06701716]\n",
            "[0.09576784 0.12487548 0.11987193 0.08066971 0.15758618 0.08776792\n",
            " 0.1356552  0.19780575]\n",
            "[0.00387158 0.10508365 0.21350988 0.00760739 0.17453973 0.20777985\n",
            " 0.1247792  0.16282872]\n",
            "[0.52412183 0.35181463 0.49153385 0.37743537 0.48968612 0.49836138\n",
            " 0.50665739 0.40641717]\n",
            "[0.185 0.152 0.137 0.125 0.116 0.107 0.096 0.082]\n",
            "1.0\n",
            "En el peor de los casos el retorno seriade 574349.9999999999\n",
            "el retorno maximo posible seria de 1024580.0000000002\n",
            "[185000. 152000. 137000. 125000. 116000. 107000.  96000.  82000.]\n",
            "1000000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No serÃ­a rentable realizar esta inversiÃ³n debido al que el riesgo de pÃ©rdida frente a la baja posibilidad de ganancia siendo mÃ¡s probable perder dinero que ganarlo ya que solo se puede dar uno de los casos a la vez por lo que al distribuir el dinero entre los posibles resultados con el fin de obtener una mayor ganancia o una ganancia segura. Se estÃ¡ perdiendo dinero esto se puede ver mejor si analizamos el mejor de los casos en retorno que es de 1024580 lo que da como margen de ganancia neto tan solo 24580 pesos sobre el 1000000 inicialmente invertido.  "
      ],
      "metadata": {
        "id": "xIhhjB0BGYgB"
      }
    }
  ]
}